\section{Conclusion}

In this report, we wanted to use Linked Open Data, along with other aggregated data, to predict which politicians have a good chance at winning a Nobel Prize. First, we selected some features we though would serve this purpose well and gathered all necessary data. While getting data from SPARQL endpoints is mostly quite straightforward, combining it with other data is not always as easy.

\begin{itemize}
	\item[$\rightarrow$] \textbf{Conclusion 1:} data that is not linked yet, is hard to gather and link.
\end{itemize}

\noindent After analysing the data, we noticed that it had to be cleaned and transformed in order to be used in learning the model. 

\begin{itemize}
	\item[$\rightarrow$] \textbf{Conclusion 2:} much publicly available data is \emph{fuzzy} and needs to be thoroughly examined before being put to use.
\end{itemize}

\noindent After we constructed final datasets, we learned and tested a model. Here, we looked for model with high precision, whereas recall didn't matter that much. Not all features performed as expected.

\begin{itemize}
	\item[$\rightarrow$] \textbf{Conclusion 3:} determining good features for difficult learning tasks is hard, especially with limited resources.
\end{itemize}

\noindent While 4 politicians were predicted as positive, we are still in slight doubt about the reliability of these predictions. That being said, the fact that we could positively predict examples, was a huge success nevertheless. 
